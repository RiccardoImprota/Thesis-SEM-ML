{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing libraries for machine learning\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from joblib import dump,load\n",
    "import shap\n",
    "\n",
    "# Display setting for exploration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment:  c:\\Users\\ricca\\anaconda3\\envs\\Thesis\\python.exe\n",
      "working directory:  C:/Users/ricca/Documents/GitHub/Thesis-SEM-ML\n"
     ]
    }
   ],
   "source": [
    "# Check out if the environment is the correct Anaconda one\n",
    "import sys\n",
    "print('environment: ',sys.executable)\n",
    "\n",
    "# Set up directory to be the github repository\n",
    "# requires git\n",
    "import os\n",
    "import subprocess\n",
    "os.getcwd()\n",
    "output = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'])\n",
    "path = output.decode('utf-8').strip()\n",
    "print('working directory: ',path)\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.DataPreparation.DataProcessor import DataProcessor\n",
    "from Source.Regression.latent_variable_regressors import GBoostRegression, RFRegression, LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the iteration n.1\n",
      "The dataframe was loaded\n",
      "A Train-Test split was performed with a test size of 0.3\n",
      "Datasets were saved\n",
      "Starting the CFA\n",
      "Starting the XGBRegressor training\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': 0.8832793527591418, 'colsample_bynode': None, 'colsample_bytree': 0.9230194998959509, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 0.0, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01584253029449818, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 4, 'max_leaves': None, 'min_child_weight': 9, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 400, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.01, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.5, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "Iteration 1 XGBoost: MSE: 0.15333474026034044, R^2: 0.6964597346788086, MAE: 0.30751859079444743, TRAIN_MSE:0.02951910181143408, TRAIN_R^2:0.9283708242606902\n",
      "Starting the Random Forest training with median imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 RandomForest: MSE: 0.15413414389679275, R^2: 0.6948772414258415, MAE: 0.30565079948242496, TRAIN_MSE:0.013463117894662778, TRAIN_R^2:0.9673312540525095\n",
      "Starting the Linear Regression training\n",
      "Iteration 1 Linear Regression: MSE: 0.14961842340465822, R^2: 0.7038165267696037, MAE: 0.2971899605318235, TRAIN_MSE:0.05598495302616047, TRAIN_R^2:0.8641504723048674\n",
      "-------------------------------------------------\n",
      "Starting the iteration n.2\n",
      "The dataframe was loaded\n",
      "A Train-Test split was performed with a test size of 0.3\n",
      "Datasets were saved\n",
      "Starting the CFA\n",
      "Starting the XGBRegressor training\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': 0.5, 'colsample_bynode': None, 'colsample_bytree': 1.0, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 0.023803239123148703, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.02093592399279847, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 10, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 359, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.01, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.5, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "Iteration 2 XGBoost: MSE: 0.05994373663025589, R^2: 0.8763883403559585, MAE: 0.19141865403653768, TRAIN_MSE:0.0597527986201618, TRAIN_R^2:0.8611344567854444\n",
      "Starting the Random Forest training with median imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n",
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 RandomForest: MSE: 0.06581157535882141, R^2: 0.8642881056269232, MAE: 0.20114015484692913, TRAIN_MSE:0.020445061654916902, TRAIN_R^2:0.9524856632939843\n",
      "Starting the Linear Regression training\n",
      "Iteration 2 Linear Regression: MSE: 0.05648890882261486, R^2: 0.8835126376235956, MAE: 0.18290838129223633, TRAIN_MSE:0.08819067830939749, TRAIN_R^2:0.7950448057212446\n",
      "-------------------------------------------------\n",
      "Starting the iteration n.3\n",
      "The dataframe was loaded\n",
      "A Train-Test split was performed with a test size of 0.3\n",
      "Datasets were saved\n",
      "Starting the CFA\n",
      "Starting the XGBRegressor training\n",
      "{'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': 1.0, 'colsample_bynode': None, 'colsample_bytree': 0.8090128411875246, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': 0.03365781658932243, 'gpu_id': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': 0.01964111308146855, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': 3, 'max_leaves': None, 'min_child_weight': 4, 'missing': nan, 'monotone_constraints': None, 'n_estimators': 400, 'n_jobs': None, 'num_parallel_tree': None, 'predictor': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.01, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': 0.5, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "Iteration 3 XGBoost: MSE: 0.12523274943117835, R^2: 0.7368622676356331, MAE: 0.27245046820506674, TRAIN_MSE:0.03704833333422526, TRAIN_R^2:0.9126777549767442\n",
      "Starting the Random Forest training with median imputation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The objective has been evaluated at this point before.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 RandomForest: MSE: 0.13656704328485217, R^2: 0.7130467689250013, MAE: 0.28536846158296, TRAIN_MSE:0.03401428176111478, TRAIN_R^2:0.9198289591210773\n",
      "Starting the Linear Regression training\n",
      "Iteration 3 Linear Regression: MSE: 0.12451818657036673, R^2: 0.738363699582786, MAE: 0.2735603171758556, TRAIN_MSE:0.06269639920148184, TRAIN_R^2:0.8522257321602631\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /=: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m#shap_values_list_RF /= montecarloiter\u001b[39;00m\n\u001b[0;32m     73\u001b[0m shap_values_list_xgb \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m montecarloiter\n\u001b[1;32m---> 74\u001b[0m shap_values_list_LM \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m montecarloiter\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /=: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "# Assuming you have data in X and y variables\n",
    "Results_RF = []\n",
    "Results_XGB = []\n",
    "Results_LM=[]\n",
    "shap_values_list_RF = None\n",
    "shap_values_list_xgb = None\n",
    "shap_values_list_LM = None\n",
    "\n",
    "montecarloiter=3\n",
    "\n",
    "for i in range(montecarloiter):\n",
    "    print(f\"Starting the iteration n.{i+1}\")\n",
    "\n",
    "    processorclass=DataProcessor()\n",
    "    processorclass.read_df()\n",
    "    processorclass.split_data(test_size=0.3)\n",
    "    processorclass.save_data()\n",
    "    processorclass.process_CFA()\n",
    "\n",
    "    X_train,y_train,X_test,y_test = processorclass.train_test_data_for_WEtarget(target_variable='WorkEngagement')\n",
    "\n",
    "    # XGBRegressor\n",
    "    Xgboost=GBoostRegression(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test)\n",
    "    Xgboost.train(verbosity=0,n_iter=90)\n",
    "    mxgbresults = Xgboost.get_results()\n",
    "    mse_xgb, r2_xgb, mae_xgb, train_mse_xgb, train_r2_xgb = (mxgbresults['mse'],mxgbresults['r2'],mxgbresults['mae'],mxgbresults['train_mse'],mxgbresults['train_r2'])\n",
    "    Results_XGB.append((mse_xgb, r2_xgb, mae_xgb,train_mse_xgb, train_r2_xgb))\n",
    "\n",
    "    if shap_values_list_xgb is None:\n",
    "        shap_values_list_xgb = Xgboost.get_shap_values()\n",
    "    else:\n",
    "        shap_values_list_xgb += Xgboost.get_shap_values()\n",
    "    print(f\"Iteration {i+1} XGBoost: MSE: {mse_xgb}, R^2: {r2_xgb}, MAE: {mae_xgb}, TRAIN_MSE:{train_mse_xgb}, TRAIN_R^2:{train_r2_xgb}\" )\n",
    "\n",
    "\n",
    "    # RandomForest\n",
    "    RFRegre=RFRegression(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test)\n",
    "    RFRegre.median_imputation()\n",
    "    RFRegre.train(verbosity=0,n_iter=30,computeshap=False)\n",
    "\n",
    "    mRFresults = RFRegre.get_results()\n",
    "    mse_RF, r2_RF, mae_RF, train_mse_RF, train_r2_RF  = (mRFresults['mse'],mRFresults['r2'],mRFresults['mae'],mRFresults['train_mse'],mRFresults['train_r2'])\n",
    "    Results_RF.append((mse_RF, r2_RF, mae_RF, train_mse_RF, train_r2_RF))\n",
    "\n",
    "\n",
    "    #if shap_values_list_RF is None:\n",
    "    #    shap_values_list_RF = RFRegre.get_shap_values()\n",
    "    #else:\n",
    "    #    shap_values_list_RF += RFRegre.get_shap_values()\n",
    "    print(f\"Iteration {i+1} RandomForest: MSE: {mse_RF}, R^2: {r2_RF}, MAE: {mae_RF}, TRAIN_MSE:{train_mse_RF}, TRAIN_R^2:{train_r2_RF}\" )\n",
    "\n",
    "\n",
    "    # Linear Regression\n",
    "    LMreg= LinearRegressionModel(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test)\n",
    "    LMreg.median_imputation()\n",
    "    LMreg.train(computeshap=True)\n",
    "    LMresults = LMreg.get_results()\n",
    "    mse_LM, r2_LM, mae_LM, train_mse_LM, train_r2_LM  = (LMresults['mse'],LMresults['r2'],LMresults['mae'],LMresults['train_mse'],LMresults['train_r2'])\n",
    "    Results_LM.append((mse_LM, r2_LM, mae_LM,train_mse_LM, train_r2_LM))\n",
    "\n",
    "    if shap_values_list_LM is None:\n",
    "        shap_values_list_LM = LMreg.get_shap_values()\n",
    "    else:\n",
    "        shap_values_list_LM += LMreg.get_shap_values()\n",
    "    print(f\"Iteration {i+1} Linear Regression: MSE: {mse_LM}, R^2: {r2_LM}, MAE: {mae_LM}, TRAIN_MSE:{train_mse_LM}, TRAIN_R^2:{train_r2_LM}\")\n",
    "\n",
    "    print((\"-------------------------------------------------\"))\n",
    "\n",
    "\n",
    "\n",
    "#shap_values_list_RF /= montecarloiter\n",
    "shap_values_list_xgb /= montecarloiter\n",
    "shap_values_list_LM /= montecarloiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_avg_metrics(Results, model_name):\n",
    "    mse_avg = np.mean([res[0] for res in Results])\n",
    "    r2_avg = np.mean([res[1] for res in Results])\n",
    "    mae_avg = np.mean([res[2] for res in Results])\n",
    "    train_mse_avg = np.mean([res[3] for res in Results])\n",
    "    train_r2_avg = np.mean([res[4] for res in Results])\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Average MSE over {montecarloiter} iterations: {mse_avg}\")\n",
    "    print(f\"Average MAE over {montecarloiter} iterations: {mae_avg}\")\n",
    "    print(f\"Average R^2 over {montecarloiter} iterations: {r2_avg}\")\n",
    "    print(f\"Average TRAIN MSE over {montecarloiter} iterations: {train_mse_avg}\")\n",
    "    print(f\"Average TRAIN R^2 over {montecarloiter} iterations: {train_r2_avg}\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "# Print the metrics for each model\n",
    "print_avg_metrics(Results_XGB, \"XGBoost\")\n",
    "print_avg_metrics(Results_RF, \"Random Forest\")\n",
    "print_avg_metrics(Results_LM, \"Linear Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.plots.beeswarm(shap_values_list_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shap.waterfall_plot(shap_values_list_xgb[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.heatmap(shap_values_list_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values_list_xgb[:, \"ProfessionalSupport\"],color=shap_values_list_xgb)\n",
    "#color=plt.get_cmap(\"cool\")\n",
    "#color=shap_values[:,\"Workclass\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
