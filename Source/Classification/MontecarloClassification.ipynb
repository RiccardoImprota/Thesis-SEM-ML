{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing libraries for machine learning\n",
    "from joblib import dump,load\n",
    "import shap\n",
    "\n",
    "# Display setting for exploration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out if the environment is the correct Anaconda one\n",
    "import sys\n",
    "print('environment: ',sys.executable)\n",
    "\n",
    "# Set up directory to be the github repository\n",
    "# requires git\n",
    "import os\n",
    "import subprocess\n",
    "os.getcwd()\n",
    "output = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'])\n",
    "path = output.decode('utf-8').strip()\n",
    "print('working directory: ',path)\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.DataPreparation.DataProcessor import DataProcessor\n",
    "from Source.Classification import GBoostClassification, LogisticRegressionClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have data in X and y variables\n",
    "Results_RF = []\n",
    "Results_XGB = []\n",
    "Results_LM=[]\n",
    "\n",
    "montecarloiter=10\n",
    "\n",
    "for i in range(montecarloiter):\n",
    "    print(f\"Starting the iteration n.{i+1}\")\n",
    "\n",
    "    processorclass=DataProcessor()\n",
    "    #processorclass.read_df()\n",
    "    #processorclass.split_data(test_size=0.3)\n",
    "    #processorclass.save_data()\n",
    "    #processorclass.process_CFA()\n",
    "\n",
    "    X_train,y_train,X_test,y_test = processorclass.train_test_data_for_WEtarget(target_variable='WorkEngagement',Categories=False)\n",
    "\n",
    "    # XGBRegressor\n",
    "    Xgboost=GBoostRegression(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test)\n",
    "    Xgboost.train(verbosity=0,n_iter=100)\n",
    "    mxgbresults = Xgboost.get_results()\n",
    "    print(mxgbresults['best_params'])\n",
    "    mse_xgb, r2_xgb, mae_xgb, train_mse_xgb, train_r2_xgb = (mxgbresults['mse'],mxgbresults['r2'],mxgbresults['mae'],mxgbresults['train_mse'],mxgbresults['train_r2'])\n",
    "    Results_XGB.append((mse_xgb, r2_xgb, mae_xgb,train_mse_xgb, train_r2_xgb))\n",
    "\n",
    "    print(f\"Iteration {i+1} XGBoost: MSE: {mse_xgb}, R^2: {r2_xgb}, MAE: {mae_xgb}, TRAIN_MSE:{train_mse_xgb}, TRAIN_R^2:{train_r2_xgb}\" )\n",
    "\n",
    "    # Linear Regression\n",
    "    LMreg= LinearRegressionModel(x_train=X_train,y_train=y_train,x_test=X_test,y_test=y_test)\n",
    "    LMreg.median_imputation()\n",
    "    LMreg.train(computeshap=True)\n",
    "    LMresults = LMreg.get_results()\n",
    "    mse_LM, r2_LM, mae_LM, train_mse_LM, train_r2_LM  = (LMresults['mse'],LMresults['r2'],LMresults['mae'],LMresults['train_mse'],LMresults['train_r2'])\n",
    "    Results_LM.append((mse_LM, r2_LM, mae_LM,train_mse_LM, train_r2_LM))\n",
    "\n",
    "    print(f\"Iteration {i+1} Linear Regression: MSE: {mse_LM}, R^2: {r2_LM}, MAE: {mae_LM}, TRAIN_MSE:{train_mse_LM}, TRAIN_R^2:{train_r2_LM}\")\n",
    "\n",
    "    print((\"-------------------------------------------------\"))\n",
    "\n",
    "        self.results[\"train_accuracy\"] = train_accuracy\n",
    "        self.results[\"train_precision\"] = train_precision\n",
    "        self.results[\"train_recall\"] = train_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_avg_metrics(Results, model_name):\n",
    "    mse_avg = np.mean([res[0] for res in Results])\n",
    "    r2_avg = np.mean([res[1] for res in Results])\n",
    "    mae_avg = np.mean([res[2] for res in Results])\n",
    "    train_mse_avg = np.mean([res[3] for res in Results])\n",
    "    train_r2_avg = np.mean([res[4] for res in Results])\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Average MSE over 10 iterations: {mse_avg}\")\n",
    "    print(f\"Average MAE over 10 iterations: {mae_avg}\")\n",
    "    print(f\"Average R^2 over 10 iterations: {r2_avg}\")\n",
    "    print(f\"Average TRAIN MSE over 10 iterations: {train_mse_avg}\")\n",
    "    print(f\"Average TRAIN R^2 over 10 iterations: {train_r2_avg}\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n",
    "# Print the metrics for each model\n",
    "print_avg_metrics(Results_XGB, \"XGBoost\")\n",
    "print_avg_metrics(Results_RF, \"Random Forest\")\n",
    "print_avg_metrics(Results_LM, \"Linear Model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
